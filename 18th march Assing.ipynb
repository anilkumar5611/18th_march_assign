{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadcb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is the Filter method in feature selection, and how does it work?\n",
    "\n",
    "# The Filter method in feature selection involves evaluating the relevance of features based on their \n",
    "# statistical properties, such as correlation with the target variable, variance, or mutual information. \n",
    "# It doesn't involve training a machine learning model; instead, it relies on predefined criteria to filter \n",
    "# out less informative features. Common techniques include correlation analysis, chi-squared tests, and information gain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "\n",
    "# The Wrapper method selects features based on their impact on the performance of a specific machine learning model.\n",
    "# It involves repeatedly training and evaluating the model with different subsets of features, and the selection process\n",
    "# is guided by the model's performance. This method is more computationally expensive compared to the Filter method but \n",
    "# can potentially result in a more optimal feature subset tailored to the specific model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58498b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "\n",
    "# Embedded methods integrate feature selection into the model training process. Techniques include:\n",
    "\n",
    "# LASSO (Least Absolute Shrinkage and Selection Operator): It adds a penalty term to the linear regression that \n",
    "#     encourages sparsity in the coefficient matrix.\n",
    "# Decision Trees: Trees can naturally perform feature selection by giving higher importance to informative features.\n",
    "# Regularized Regression: Techniques like Ridge and Elastic Net regression include regularization terms that penalize \n",
    "#     the coefficients of less important features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "\n",
    "# It may overlook interactions between features that collectively contribute to predictive power.\n",
    "# It doesn't consider the impact of feature selection on the performance of a specific machine learning model.\n",
    "# Filter methods might eliminate redundant features but may retain correlated features, leading to multicollinearity issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c23e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
    "\n",
    "# Use the Filter method when:\n",
    "\n",
    "# You have a large dataset, and the computational cost of Wrapper methods is prohibitive.\n",
    "# You want a quick and computationally less intensive way to reduce the feature space.\n",
    "# There's a need for a simple, interpretable feature selection process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f084d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn. Describe\n",
    "# how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "\n",
    "# Conduct correlation analysis to identify features strongly correlated with customer churn.\n",
    "# Use statistical tests such as chi-squared or mutual information to assess the relevance of categorical features.\n",
    "# Evaluate variance to identify features with low variability, as they might not contribute much to predicting churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. You are working on a project to predict the outcome of a soccer match. Explain how you would use the Embedded\n",
    "# method to select the most relevant features for the model.\n",
    "\n",
    "# Train a machine learning model (e.g., a classifier or regression model) on the dataset with all features.\n",
    "# Analyze the learned coefficients or feature importances from the model.\n",
    "# Select features with higher coefficients or importances, as they contribute more to the model's predictive power.\n",
    "# Fine-tune the model and repeat the process until an optimal set of features is achieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. You are working on a project to predict the price of a house based on its features, such as size, location, and age. \n",
    "# Explain how you would use the Wrapper method to select the best set of features for the predictor.\n",
    "\n",
    "# Use a subset of features and train a model (e.g., a regression model) on the dataset.\n",
    "# Evaluate the model's performance using a relevant metric (e.g., Mean Squared Error for regression).\n",
    "# Iteratively add or remove features and retrain the model to find the subset that maximizes predictive performance.\n",
    "# Choose the set of features that results in the best model performance on a validation set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
